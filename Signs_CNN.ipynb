{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "c4f7034e",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "aa1b6aed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import numpy as np\n",
    "import h5py\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "import tensorflow.keras.layers as tfl\n",
    "\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b3fcdee",
   "metadata": {},
   "source": [
    "### Load data and split into train/test sets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f1606cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_signs_dataset():\n",
    "    train_dataset = h5py.File('datasets/train_signs.h5', \"r\")\n",
    "    train_set_x_orig = np.array(train_dataset[\"train_set_x\"][:]) # train set features\n",
    "    train_set_y_orig = np.array(train_dataset[\"train_set_y\"][:]) # train set labels\n",
    "\n",
    "    test_dataset = h5py.File('datasets/test_signs.h5', \"r\")\n",
    "    test_set_x_orig = np.array(test_dataset[\"test_set_x\"][:]) # test set features\n",
    "    test_set_y_orig = np.array(test_dataset[\"test_set_y\"][:]) # test set labels\n",
    "\n",
    "    classes = np.array(test_dataset[\"list_classes\"][:]) # list of classes\n",
    "    \n",
    "    train_set_y_orig = train_set_y_orig.reshape((1, train_set_y_orig.shape[0]))\n",
    "    test_set_y_orig = test_set_y_orig.reshape((1, test_set_y_orig.shape[0]))\n",
    "    \n",
    "    return train_set_x_orig, train_set_y_orig, test_set_x_orig, test_set_y_orig, classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "b72d0462",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convert_to_one_hot(Y, C):\n",
    "    Y = np.eye(C)[Y.reshape(-1)].T\n",
    "    return Y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "86cd8838",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "number of training examples = 1080\n",
      "number of test examples = 120\n",
      "X_train shape: (1080, 64, 64, 3)\n",
      "Y_train shape: (1080, 6)\n",
      "X_test shape: (120, 64, 64, 3)\n",
      "Y_test shape: (120, 6)\n"
     ]
    }
   ],
   "source": [
    "# Loading the data (signs)\n",
    "X_train_orig, Y_train_orig, X_test_orig, Y_test_orig, classes = load_signs_dataset()\n",
    "\n",
    "X_train = X_train_orig/255.\n",
    "X_test = X_test_orig/255.\n",
    "\n",
    "Y_train = convert_to_one_hot(Y_train_orig, 6).T\n",
    "Y_test = convert_to_one_hot(Y_test_orig, 6).T\n",
    "\n",
    "print (\"number of training examples = \" + str(X_train.shape[0]))\n",
    "print (\"number of test examples = \" + str(X_test.shape[0]))\n",
    "print (\"X_train shape: \" + str(X_train.shape))\n",
    "print (\"Y_train shape: \" + str(Y_train.shape))\n",
    "print (\"X_test shape: \" + str(X_test.shape))\n",
    "print (\"Y_test shape: \" + str(Y_test.shape))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a6a29414",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "y = 5\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Example of an image from the dataset\n",
    "index = 300\n",
    "plt.imshow(X_train_orig[index])\n",
    "print (\"y = \" + str(np.squeeze(Y_train_orig[:, index])))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "57ce6130",
   "metadata": {},
   "source": [
    "### TF Keras Functional API"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "58db05fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def convolutional_model(input_shape):\n",
    "    \"\"\"\n",
    "    Implements the forward propagation for the model:\n",
    "    CONV2D -> RELU -> MAXPOOL -> CONV2D -> RELU -> MAXPOOL -> FLATTEN -> DENSE\n",
    "    \n",
    "    We'll hard-code some values\n",
    "    such as the stride and kernel (filter) sizes. \n",
    "    Normally, functions should take these values as function parameters.\n",
    "    \n",
    "    Arguments:\n",
    "    input_img -- input dataset, of shape (input_shape)\n",
    "\n",
    "    Returns:\n",
    "    model -- TF Keras model (object containing the information for the entire training process) \n",
    "    \"\"\"\n",
    "\n",
    "    input_img = tf.keras.Input(shape=input_shape)\n",
    "    ## CONV2D: 8 filters 4x4, stride of 1, padding 'SAME'\n",
    "    ## RELU\n",
    "    ## MAXPOOL: window 8x8, stride 8, padding 'SAME'\n",
    "    ## CONV2D: 16 filters 2x2, stride 1, padding 'SAME'\n",
    "    ## RELU\n",
    "    ## MAXPOOL: window 4x4, stride 4, padding 'SAME'\n",
    "    ## FLATTEN\n",
    "    ## Dense layer\n",
    "    ## 6 neurons in output layer \n",
    "    # outputs\n",
    "\n",
    "    Z1 = tfl.Conv2D(filters = 8,kernel_size = 4,strides=(1,1),padding='same')(input_img)\n",
    "    A1 = tfl.ReLU()(Z1)\n",
    "    P1 = tfl.MaxPool2D(pool_size=(8, 8), strides=(8, 8), padding='same')(A1)\n",
    "    Z2 = tfl.Conv2D(filters = 16,kernel_size = 2,strides=(1,1),padding='same')(P1)\n",
    "    A2 = tfl.ReLU()(Z2)\n",
    "    P2 = tfl.MaxPool2D(pool_size=(4, 4), strides=(4, 4), padding='same')(A2)\n",
    "    F = tfl.Flatten()(P2)\n",
    "    outputs = tfl.Dense(units=6, activation='softmax')(F)\n",
    "    \n",
    "    model = tf.keras.Model(inputs=input_img, outputs=outputs)\n",
    "    return model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "f590539a",
   "metadata": {},
   "outputs": [],
   "source": [
    "conv_model = convolutional_model((64, 64, 3))\n",
    "conv_model.compile(optimizer='adam',loss='categorical_crossentropy',metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f297d5f1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Model: \"model_3\"\n",
      "_________________________________________________________________\n",
      " Layer (type)                Output Shape              Param #   \n",
      "=================================================================\n",
      " input_4 (InputLayer)        [(None, 64, 64, 3)]       0         \n",
      "                                                                 \n",
      " conv2d_6 (Conv2D)           (None, 64, 64, 8)         392       \n",
      "                                                                 \n",
      " re_lu_6 (ReLU)              (None, 64, 64, 8)         0         \n",
      "                                                                 \n",
      " max_pooling2d_6 (MaxPooling  (None, 8, 8, 8)          0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " conv2d_7 (Conv2D)           (None, 8, 8, 16)          528       \n",
      "                                                                 \n",
      " re_lu_7 (ReLU)              (None, 8, 8, 16)          0         \n",
      "                                                                 \n",
      " max_pooling2d_7 (MaxPooling  (None, 2, 2, 16)         0         \n",
      " 2D)                                                             \n",
      "                                                                 \n",
      " flatten_3 (Flatten)         (None, 64)                0         \n",
      "                                                                 \n",
      " dense_3 (Dense)             (None, 6)                 390       \n",
      "                                                                 \n",
      "=================================================================\n",
      "Total params: 1,310\n",
      "Trainable params: 1,310\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "conv_model.summary()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "16b3b9f8",
   "metadata": {},
   "source": [
    "### Train the Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ad9a925e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4257 - accuracy: 0.8657 - val_loss: 0.4843 - val_accuracy: 0.8500\n",
      "Epoch 2/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4223 - accuracy: 0.8648 - val_loss: 0.4810 - val_accuracy: 0.8583\n",
      "Epoch 3/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4191 - accuracy: 0.8657 - val_loss: 0.4778 - val_accuracy: 0.8583\n",
      "Epoch 4/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.4159 - accuracy: 0.8685 - val_loss: 0.4748 - val_accuracy: 0.8500\n",
      "Epoch 5/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4128 - accuracy: 0.8685 - val_loss: 0.4718 - val_accuracy: 0.8500\n",
      "Epoch 6/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.4097 - accuracy: 0.8704 - val_loss: 0.4689 - val_accuracy: 0.8500\n",
      "Epoch 7/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4066 - accuracy: 0.8731 - val_loss: 0.4663 - val_accuracy: 0.8500\n",
      "Epoch 8/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4036 - accuracy: 0.8750 - val_loss: 0.4633 - val_accuracy: 0.8500\n",
      "Epoch 9/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.4007 - accuracy: 0.8769 - val_loss: 0.4602 - val_accuracy: 0.8500\n",
      "Epoch 10/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3976 - accuracy: 0.8769 - val_loss: 0.4572 - val_accuracy: 0.8500\n",
      "Epoch 11/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3945 - accuracy: 0.8806 - val_loss: 0.4548 - val_accuracy: 0.8500\n",
      "Epoch 12/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3917 - accuracy: 0.8806 - val_loss: 0.4519 - val_accuracy: 0.8500\n",
      "Epoch 13/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3890 - accuracy: 0.8815 - val_loss: 0.4494 - val_accuracy: 0.8500\n",
      "Epoch 14/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3863 - accuracy: 0.8815 - val_loss: 0.4471 - val_accuracy: 0.8500\n",
      "Epoch 15/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3836 - accuracy: 0.8843 - val_loss: 0.4441 - val_accuracy: 0.8500\n",
      "Epoch 16/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3810 - accuracy: 0.8852 - val_loss: 0.4417 - val_accuracy: 0.8500\n",
      "Epoch 17/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3783 - accuracy: 0.8852 - val_loss: 0.4388 - val_accuracy: 0.8500\n",
      "Epoch 18/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3759 - accuracy: 0.8880 - val_loss: 0.4363 - val_accuracy: 0.8583\n",
      "Epoch 19/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3731 - accuracy: 0.8880 - val_loss: 0.4336 - val_accuracy: 0.8583\n",
      "Epoch 20/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3708 - accuracy: 0.8898 - val_loss: 0.4310 - val_accuracy: 0.8583\n",
      "Epoch 21/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3682 - accuracy: 0.8889 - val_loss: 0.4289 - val_accuracy: 0.8583\n",
      "Epoch 22/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3655 - accuracy: 0.8926 - val_loss: 0.4260 - val_accuracy: 0.8583\n",
      "Epoch 23/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3629 - accuracy: 0.8935 - val_loss: 0.4243 - val_accuracy: 0.8583\n",
      "Epoch 24/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3606 - accuracy: 0.8935 - val_loss: 0.4220 - val_accuracy: 0.8583\n",
      "Epoch 25/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3582 - accuracy: 0.8935 - val_loss: 0.4195 - val_accuracy: 0.8583\n",
      "Epoch 26/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3559 - accuracy: 0.8926 - val_loss: 0.4173 - val_accuracy: 0.8583\n",
      "Epoch 27/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3535 - accuracy: 0.8935 - val_loss: 0.4157 - val_accuracy: 0.8583\n",
      "Epoch 28/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3513 - accuracy: 0.8972 - val_loss: 0.4133 - val_accuracy: 0.8583\n",
      "Epoch 29/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3488 - accuracy: 0.8972 - val_loss: 0.4111 - val_accuracy: 0.8583\n",
      "Epoch 30/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3465 - accuracy: 0.8972 - val_loss: 0.4095 - val_accuracy: 0.8583\n",
      "Epoch 31/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.3444 - accuracy: 0.8981 - val_loss: 0.4075 - val_accuracy: 0.8583\n",
      "Epoch 32/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3422 - accuracy: 0.8991 - val_loss: 0.4058 - val_accuracy: 0.8583\n",
      "Epoch 33/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3397 - accuracy: 0.9019 - val_loss: 0.4040 - val_accuracy: 0.8583\n",
      "Epoch 34/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3376 - accuracy: 0.9019 - val_loss: 0.4023 - val_accuracy: 0.8583\n",
      "Epoch 35/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3351 - accuracy: 0.9019 - val_loss: 0.4005 - val_accuracy: 0.8583\n",
      "Epoch 36/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3331 - accuracy: 0.9037 - val_loss: 0.3989 - val_accuracy: 0.8583\n",
      "Epoch 37/100\n",
      "17/17 [==============================] - 0s 25ms/step - loss: 0.3309 - accuracy: 0.9046 - val_loss: 0.3970 - val_accuracy: 0.8583\n",
      "Epoch 38/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3287 - accuracy: 0.9046 - val_loss: 0.3959 - val_accuracy: 0.8583\n",
      "Epoch 39/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3266 - accuracy: 0.9065 - val_loss: 0.3938 - val_accuracy: 0.8583\n",
      "Epoch 40/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3244 - accuracy: 0.9083 - val_loss: 0.3923 - val_accuracy: 0.8583\n",
      "Epoch 41/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.3223 - accuracy: 0.9074 - val_loss: 0.3916 - val_accuracy: 0.8583\n",
      "Epoch 42/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3203 - accuracy: 0.9083 - val_loss: 0.3898 - val_accuracy: 0.8667\n",
      "Epoch 43/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3183 - accuracy: 0.9093 - val_loss: 0.3885 - val_accuracy: 0.8667\n",
      "Epoch 44/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3162 - accuracy: 0.9102 - val_loss: 0.3871 - val_accuracy: 0.8667\n",
      "Epoch 45/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3142 - accuracy: 0.9111 - val_loss: 0.3858 - val_accuracy: 0.8667\n",
      "Epoch 46/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3123 - accuracy: 0.9120 - val_loss: 0.3844 - val_accuracy: 0.8667\n",
      "Epoch 47/100\n",
      "17/17 [==============================] - 0s 26ms/step - loss: 0.3101 - accuracy: 0.9130 - val_loss: 0.3824 - val_accuracy: 0.8667\n",
      "Epoch 48/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.3082 - accuracy: 0.9130 - val_loss: 0.3817 - val_accuracy: 0.8667\n",
      "Epoch 49/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.3062 - accuracy: 0.9130 - val_loss: 0.3798 - val_accuracy: 0.8667\n",
      "Epoch 50/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.3044 - accuracy: 0.9139 - val_loss: 0.3788 - val_accuracy: 0.8667\n",
      "Epoch 51/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.3028 - accuracy: 0.9139 - val_loss: 0.3768 - val_accuracy: 0.8667\n",
      "Epoch 52/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.3004 - accuracy: 0.9139 - val_loss: 0.3761 - val_accuracy: 0.8667\n",
      "Epoch 53/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2987 - accuracy: 0.9157 - val_loss: 0.3746 - val_accuracy: 0.8667\n",
      "Epoch 54/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2965 - accuracy: 0.9148 - val_loss: 0.3735 - val_accuracy: 0.8667\n",
      "Epoch 55/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2947 - accuracy: 0.9176 - val_loss: 0.3722 - val_accuracy: 0.8667\n",
      "Epoch 56/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.2930 - accuracy: 0.9185 - val_loss: 0.3704 - val_accuracy: 0.8667\n",
      "Epoch 57/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2908 - accuracy: 0.9185 - val_loss: 0.3695 - val_accuracy: 0.8667\n",
      "Epoch 58/100\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "17/17 [==============================] - 0s 30ms/step - loss: 0.2890 - accuracy: 0.9185 - val_loss: 0.3683 - val_accuracy: 0.8667\n",
      "Epoch 59/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2873 - accuracy: 0.9185 - val_loss: 0.3665 - val_accuracy: 0.8667\n",
      "Epoch 60/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2854 - accuracy: 0.9194 - val_loss: 0.3654 - val_accuracy: 0.8667\n",
      "Epoch 61/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2835 - accuracy: 0.9204 - val_loss: 0.3639 - val_accuracy: 0.8667\n",
      "Epoch 62/100\n",
      "17/17 [==============================] - 1s 32ms/step - loss: 0.2819 - accuracy: 0.9222 - val_loss: 0.3636 - val_accuracy: 0.8667\n",
      "Epoch 63/100\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.2800 - accuracy: 0.9204 - val_loss: 0.3617 - val_accuracy: 0.8667\n",
      "Epoch 64/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2783 - accuracy: 0.9213 - val_loss: 0.3609 - val_accuracy: 0.8667\n",
      "Epoch 65/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2769 - accuracy: 0.9213 - val_loss: 0.3598 - val_accuracy: 0.8667\n",
      "Epoch 66/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2752 - accuracy: 0.9222 - val_loss: 0.3591 - val_accuracy: 0.8667\n",
      "Epoch 67/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2736 - accuracy: 0.9213 - val_loss: 0.3586 - val_accuracy: 0.8667\n",
      "Epoch 68/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2716 - accuracy: 0.9231 - val_loss: 0.3569 - val_accuracy: 0.8667\n",
      "Epoch 69/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2703 - accuracy: 0.9250 - val_loss: 0.3552 - val_accuracy: 0.8750\n",
      "Epoch 70/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2682 - accuracy: 0.9241 - val_loss: 0.3552 - val_accuracy: 0.8750\n",
      "Epoch 71/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2669 - accuracy: 0.9269 - val_loss: 0.3538 - val_accuracy: 0.8750\n",
      "Epoch 72/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2649 - accuracy: 0.9250 - val_loss: 0.3528 - val_accuracy: 0.8750\n",
      "Epoch 73/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2633 - accuracy: 0.9269 - val_loss: 0.3513 - val_accuracy: 0.8750\n",
      "Epoch 74/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2617 - accuracy: 0.9269 - val_loss: 0.3501 - val_accuracy: 0.8833\n",
      "Epoch 75/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2598 - accuracy: 0.9287 - val_loss: 0.3496 - val_accuracy: 0.8833\n",
      "Epoch 76/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2587 - accuracy: 0.9287 - val_loss: 0.3486 - val_accuracy: 0.8833\n",
      "Epoch 77/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2570 - accuracy: 0.9296 - val_loss: 0.3471 - val_accuracy: 0.8833\n",
      "Epoch 78/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2552 - accuracy: 0.9296 - val_loss: 0.3469 - val_accuracy: 0.8833\n",
      "Epoch 79/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2540 - accuracy: 0.9296 - val_loss: 0.3458 - val_accuracy: 0.8833\n",
      "Epoch 80/100\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.2522 - accuracy: 0.9306 - val_loss: 0.3444 - val_accuracy: 0.8833\n",
      "Epoch 81/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2507 - accuracy: 0.9296 - val_loss: 0.3437 - val_accuracy: 0.8833\n",
      "Epoch 82/100\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.2491 - accuracy: 0.9315 - val_loss: 0.3432 - val_accuracy: 0.8833\n",
      "Epoch 83/100\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.2478 - accuracy: 0.9306 - val_loss: 0.3419 - val_accuracy: 0.8833\n",
      "Epoch 84/100\n",
      "17/17 [==============================] - 1s 31ms/step - loss: 0.2463 - accuracy: 0.9324 - val_loss: 0.3412 - val_accuracy: 0.8833\n",
      "Epoch 85/100\n",
      "17/17 [==============================] - 1s 30ms/step - loss: 0.2448 - accuracy: 0.9315 - val_loss: 0.3394 - val_accuracy: 0.8917\n",
      "Epoch 86/100\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.2434 - accuracy: 0.9324 - val_loss: 0.3390 - val_accuracy: 0.8917\n",
      "Epoch 87/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2421 - accuracy: 0.9333 - val_loss: 0.3379 - val_accuracy: 0.8917\n",
      "Epoch 88/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2405 - accuracy: 0.9343 - val_loss: 0.3370 - val_accuracy: 0.8917\n",
      "Epoch 89/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2390 - accuracy: 0.9333 - val_loss: 0.3352 - val_accuracy: 0.8917\n",
      "Epoch 90/100\n",
      "17/17 [==============================] - 1s 33ms/step - loss: 0.2376 - accuracy: 0.9352 - val_loss: 0.3342 - val_accuracy: 0.8917\n",
      "Epoch 91/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2360 - accuracy: 0.9352 - val_loss: 0.3334 - val_accuracy: 0.8917\n",
      "Epoch 92/100\n",
      "17/17 [==============================] - 0s 30ms/step - loss: 0.2346 - accuracy: 0.9361 - val_loss: 0.3323 - val_accuracy: 0.8917\n",
      "Epoch 93/100\n",
      "17/17 [==============================] - 1s 29ms/step - loss: 0.2332 - accuracy: 0.9352 - val_loss: 0.3318 - val_accuracy: 0.8917\n",
      "Epoch 94/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2319 - accuracy: 0.9361 - val_loss: 0.3311 - val_accuracy: 0.8917\n",
      "Epoch 95/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2306 - accuracy: 0.9389 - val_loss: 0.3293 - val_accuracy: 0.8917\n",
      "Epoch 96/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2291 - accuracy: 0.9380 - val_loss: 0.3291 - val_accuracy: 0.8917\n",
      "Epoch 97/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2279 - accuracy: 0.9389 - val_loss: 0.3282 - val_accuracy: 0.8917\n",
      "Epoch 98/100\n",
      "17/17 [==============================] - 0s 27ms/step - loss: 0.2265 - accuracy: 0.9380 - val_loss: 0.3259 - val_accuracy: 0.9000\n",
      "Epoch 99/100\n",
      "17/17 [==============================] - 0s 29ms/step - loss: 0.2252 - accuracy: 0.9389 - val_loss: 0.3261 - val_accuracy: 0.8917\n",
      "Epoch 100/100\n",
      "17/17 [==============================] - 0s 28ms/step - loss: 0.2241 - accuracy: 0.9398 - val_loss: 0.3252 - val_accuracy: 0.9000\n"
     ]
    }
   ],
   "source": [
    "train_dataset = tf.data.Dataset.from_tensor_slices((X_train, Y_train)).batch(64)\n",
    "test_dataset = tf.data.Dataset.from_tensor_slices((X_test, Y_test)).batch(64)\n",
    "history = conv_model.fit(train_dataset, epochs=100, validation_data=test_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "54cab485",
   "metadata": {},
   "source": [
    "<a name='5'></a>\n",
    "###  History Object \n",
    "\n",
    "The history object is an output of the `.fit()` operation, and provides a record of all the loss and metric values in memory. It's stored as a dictionary that we can retrieve at `history.history`: "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "d6c5d1a3",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'loss': [0.4257359802722931,\n",
       "  0.42225632071495056,\n",
       "  0.41914764046669006,\n",
       "  0.4159003794193268,\n",
       "  0.4127584397792816,\n",
       "  0.4096514880657196,\n",
       "  0.40655818581581116,\n",
       "  0.4035669267177582,\n",
       "  0.4007101356983185,\n",
       "  0.39757320284843445,\n",
       "  0.39450138807296753,\n",
       "  0.3916662633419037,\n",
       "  0.38898909091949463,\n",
       "  0.38632622361183167,\n",
       "  0.38355782628059387,\n",
       "  0.3810115456581116,\n",
       "  0.3783228397369385,\n",
       "  0.37593764066696167,\n",
       "  0.3730720281600952,\n",
       "  0.37078937888145447,\n",
       "  0.36818593740463257,\n",
       "  0.365458607673645,\n",
       "  0.36293187737464905,\n",
       "  0.3605636656284332,\n",
       "  0.3581647276878357,\n",
       "  0.35592567920684814,\n",
       "  0.3535435199737549,\n",
       "  0.3513248562812805,\n",
       "  0.34882816672325134,\n",
       "  0.34649473428726196,\n",
       "  0.34440842270851135,\n",
       "  0.3421977758407593,\n",
       "  0.33969736099243164,\n",
       "  0.33757928013801575,\n",
       "  0.3351455628871918,\n",
       "  0.33310267329216003,\n",
       "  0.33094140887260437,\n",
       "  0.32874709367752075,\n",
       "  0.3266482949256897,\n",
       "  0.3243849277496338,\n",
       "  0.32233837246894836,\n",
       "  0.3203354775905609,\n",
       "  0.3182847797870636,\n",
       "  0.3161991238594055,\n",
       "  0.3142419159412384,\n",
       "  0.3122805655002594,\n",
       "  0.3100624680519104,\n",
       "  0.30817538499832153,\n",
       "  0.3062131106853485,\n",
       "  0.30443528294563293,\n",
       "  0.3027593791484833,\n",
       "  0.3004002273082733,\n",
       "  0.29865214228630066,\n",
       "  0.2964732050895691,\n",
       "  0.29467451572418213,\n",
       "  0.29296034574508667,\n",
       "  0.2907935082912445,\n",
       "  0.28901365399360657,\n",
       "  0.28725460171699524,\n",
       "  0.28540730476379395,\n",
       "  0.2835334837436676,\n",
       "  0.28185343742370605,\n",
       "  0.27997887134552,\n",
       "  0.2782815396785736,\n",
       "  0.2768919765949249,\n",
       "  0.27519938349723816,\n",
       "  0.2735510766506195,\n",
       "  0.2715831398963928,\n",
       "  0.2702896296977997,\n",
       "  0.26818791031837463,\n",
       "  0.266922265291214,\n",
       "  0.26494771242141724,\n",
       "  0.2633199095726013,\n",
       "  0.2617422044277191,\n",
       "  0.25984564423561096,\n",
       "  0.2586910128593445,\n",
       "  0.2569732367992401,\n",
       "  0.25522637367248535,\n",
       "  0.2539883553981781,\n",
       "  0.25223055481910706,\n",
       "  0.25065749883651733,\n",
       "  0.24913516640663147,\n",
       "  0.24780049920082092,\n",
       "  0.24630536139011383,\n",
       "  0.24482585489749908,\n",
       "  0.2433536946773529,\n",
       "  0.24210023880004883,\n",
       "  0.24052448570728302,\n",
       "  0.2390448898077011,\n",
       "  0.23756055533885956,\n",
       "  0.23604968190193176,\n",
       "  0.23461304605007172,\n",
       "  0.23321469128131866,\n",
       "  0.23190899193286896,\n",
       "  0.23062196373939514,\n",
       "  0.22913680970668793,\n",
       "  0.2278727889060974,\n",
       "  0.22654561698436737,\n",
       "  0.22515332698822021,\n",
       "  0.22406445443630219],\n",
       " 'accuracy': [0.8657407164573669,\n",
       "  0.864814817905426,\n",
       "  0.8657407164573669,\n",
       "  0.8685185313224792,\n",
       "  0.8685185313224792,\n",
       "  0.8703703880310059,\n",
       "  0.8731481432914734,\n",
       "  0.875,\n",
       "  0.8768518567085266,\n",
       "  0.8768518567085266,\n",
       "  0.8805555701255798,\n",
       "  0.8805555701255798,\n",
       "  0.8814814686775208,\n",
       "  0.8814814686775208,\n",
       "  0.8842592835426331,\n",
       "  0.885185182094574,\n",
       "  0.885185182094574,\n",
       "  0.8879629373550415,\n",
       "  0.8879629373550415,\n",
       "  0.8898147940635681,\n",
       "  0.8888888955116272,\n",
       "  0.8925926089286804,\n",
       "  0.8935185074806213,\n",
       "  0.8935185074806213,\n",
       "  0.8935185074806213,\n",
       "  0.8925926089286804,\n",
       "  0.8935185074806213,\n",
       "  0.8972222208976746,\n",
       "  0.8972222208976746,\n",
       "  0.8972222208976746,\n",
       "  0.8981481194496155,\n",
       "  0.8990740776062012,\n",
       "  0.9018518328666687,\n",
       "  0.9018518328666687,\n",
       "  0.9018518328666687,\n",
       "  0.9037036895751953,\n",
       "  0.904629647731781,\n",
       "  0.904629647731781,\n",
       "  0.9064815044403076,\n",
       "  0.9083333611488342,\n",
       "  0.9074074029922485,\n",
       "  0.9083333611488342,\n",
       "  0.9092592597007751,\n",
       "  0.9101851582527161,\n",
       "  0.9111111164093018,\n",
       "  0.9120370149612427,\n",
       "  0.9129629731178284,\n",
       "  0.9129629731178284,\n",
       "  0.9129629731178284,\n",
       "  0.9138888716697693,\n",
       "  0.9138888716697693,\n",
       "  0.9138888716697693,\n",
       "  0.9157407283782959,\n",
       "  0.914814829826355,\n",
       "  0.9175925850868225,\n",
       "  0.9185185432434082,\n",
       "  0.9185185432434082,\n",
       "  0.9185185432434082,\n",
       "  0.9185185432434082,\n",
       "  0.9194444417953491,\n",
       "  0.9203703999519348,\n",
       "  0.9222221970558167,\n",
       "  0.9203703999519348,\n",
       "  0.9212962985038757,\n",
       "  0.9212962985038757,\n",
       "  0.9222221970558167,\n",
       "  0.9212962985038757,\n",
       "  0.9231481552124023,\n",
       "  0.925000011920929,\n",
       "  0.9240740537643433,\n",
       "  0.9268518686294556,\n",
       "  0.925000011920929,\n",
       "  0.9268518686294556,\n",
       "  0.9268518686294556,\n",
       "  0.9287037253379822,\n",
       "  0.9287037253379822,\n",
       "  0.9296296238899231,\n",
       "  0.9296296238899231,\n",
       "  0.9296296238899231,\n",
       "  0.9305555820465088,\n",
       "  0.9296296238899231,\n",
       "  0.9314814805984497,\n",
       "  0.9305555820465088,\n",
       "  0.9324073791503906,\n",
       "  0.9314814805984497,\n",
       "  0.9324073791503906,\n",
       "  0.9333333373069763,\n",
       "  0.9342592358589172,\n",
       "  0.9333333373069763,\n",
       "  0.9351851940155029,\n",
       "  0.9351851940155029,\n",
       "  0.9361110925674438,\n",
       "  0.9351851940155029,\n",
       "  0.9361110925674438,\n",
       "  0.9388889074325562,\n",
       "  0.9379629492759705,\n",
       "  0.9388889074325562,\n",
       "  0.9379629492759705,\n",
       "  0.9388889074325562,\n",
       "  0.9398148059844971],\n",
       " 'val_loss': [0.48426520824432373,\n",
       "  0.48099085688591003,\n",
       "  0.47779521346092224,\n",
       "  0.47483518719673157,\n",
       "  0.47177404165267944,\n",
       "  0.4688973128795624,\n",
       "  0.4662514328956604,\n",
       "  0.46328794956207275,\n",
       "  0.46018746495246887,\n",
       "  0.4572024345397949,\n",
       "  0.4547589421272278,\n",
       "  0.45186325907707214,\n",
       "  0.4493941068649292,\n",
       "  0.447070449590683,\n",
       "  0.44408443570137024,\n",
       "  0.44169971346855164,\n",
       "  0.4388335645198822,\n",
       "  0.43630555272102356,\n",
       "  0.43358248472213745,\n",
       "  0.430984765291214,\n",
       "  0.4289323091506958,\n",
       "  0.4260457158088684,\n",
       "  0.4243116080760956,\n",
       "  0.42197445034980774,\n",
       "  0.41949203610420227,\n",
       "  0.4173458218574524,\n",
       "  0.41571521759033203,\n",
       "  0.4132855236530304,\n",
       "  0.4111374616622925,\n",
       "  0.40951186418533325,\n",
       "  0.4075242280960083,\n",
       "  0.40582963824272156,\n",
       "  0.4040292799472809,\n",
       "  0.4022728502750397,\n",
       "  0.40050360560417175,\n",
       "  0.3988721966743469,\n",
       "  0.39697349071502686,\n",
       "  0.3959290087223053,\n",
       "  0.39378994703292847,\n",
       "  0.3922862410545349,\n",
       "  0.3915547728538513,\n",
       "  0.38975733518600464,\n",
       "  0.38851773738861084,\n",
       "  0.38709691166877747,\n",
       "  0.38577574491500854,\n",
       "  0.38437774777412415,\n",
       "  0.38239678740501404,\n",
       "  0.3817475140094757,\n",
       "  0.37979620695114136,\n",
       "  0.378842294216156,\n",
       "  0.3768267333507538,\n",
       "  0.376071572303772,\n",
       "  0.3746287226676941,\n",
       "  0.3734721541404724,\n",
       "  0.3721681535243988,\n",
       "  0.37042590975761414,\n",
       "  0.3694668412208557,\n",
       "  0.36833640933036804,\n",
       "  0.3664815127849579,\n",
       "  0.3653542101383209,\n",
       "  0.3638606071472168,\n",
       "  0.3635667562484741,\n",
       "  0.36167940497398376,\n",
       "  0.3609299063682556,\n",
       "  0.35981330275535583,\n",
       "  0.3591446876525879,\n",
       "  0.3586249053478241,\n",
       "  0.3568649888038635,\n",
       "  0.35516875982284546,\n",
       "  0.35522931814193726,\n",
       "  0.35376766324043274,\n",
       "  0.3528062105178833,\n",
       "  0.3513445258140564,\n",
       "  0.3501032590866089,\n",
       "  0.3496331572532654,\n",
       "  0.3486001193523407,\n",
       "  0.3471372723579407,\n",
       "  0.34691351652145386,\n",
       "  0.345818430185318,\n",
       "  0.3444174528121948,\n",
       "  0.34371915459632874,\n",
       "  0.34315595030784607,\n",
       "  0.3419421911239624,\n",
       "  0.34124755859375,\n",
       "  0.33942079544067383,\n",
       "  0.3389694094657898,\n",
       "  0.3378616273403168,\n",
       "  0.33696943521499634,\n",
       "  0.3352438509464264,\n",
       "  0.3342331647872925,\n",
       "  0.33336466550827026,\n",
       "  0.33233481645584106,\n",
       "  0.33183300495147705,\n",
       "  0.33108195662498474,\n",
       "  0.3293427526950836,\n",
       "  0.3291098177433014,\n",
       "  0.32820403575897217,\n",
       "  0.3259478807449341,\n",
       "  0.326113760471344,\n",
       "  0.3252301514148712],\n",
       " 'val_accuracy': [0.8500000238418579,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8500000238418579,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8583333492279053,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.8666666746139526,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.875,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8833333253860474,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8916666507720947,\n",
       "  0.8999999761581421,\n",
       "  0.8916666507720947,\n",
       "  0.8999999761581421]}"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "history.history"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
